{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc977921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc4824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_features(path='/home/NAS_mount/yslee/dataset/clinical_features_0811.csv'):\n",
    "    df=pd.read_csv(path,encoding='CP949')\n",
    "    df=df[['P_No','CV','PF','ST','PA','FV','CD','RR','PS','TM','BRG']]\n",
    "    \n",
    "    label_file=pd.read_csv('/home/NAS_mount/yslee/dataset/premolar_labels_0810.csv')\n",
    "    label_file=label_file.set_index('PatientID_new')\n",
    "    \n",
    "    P_No_old_list=[]\n",
    "    label_list=[]\n",
    "    for i in range(0,len(df)):\n",
    "        P_No_old_list.append(label_file['PatientID'][df['P_No'][i]])\n",
    "        label_list.append(label_file['Result'][df['P_No'][i]])\n",
    "    df=pd.concat([pd.DataFrame(P_No_old_list),df,pd.DataFrame(label_list)],axis=1)\n",
    "\n",
    "    df.columns=['P_No_old','P_No','CV','PF','ST','PA','FV','CD','RR','PS','TM','BRG','Result']\n",
    "    df=df.set_index('P_No')\n",
    "    \n",
    "    features=df[['CV','PF','ST','PA','FV','CD','RR','PS','TM','BRG']]\n",
    "    label=df['Result']\n",
    "\n",
    "    '''for i in range(0,len(features)):\n",
    "        for j in range(0,len(features.iloc[i])):\n",
    "            if features.iloc[i,j]=='Y':\n",
    "                features.iloc[i,j]=np.float32(1)\n",
    "            elif features.iloc[i,j]=='N':\n",
    "                features.iloc[i,j]=np.float32(0)\n",
    "            \n",
    "    for i in range(0,len(label)):\n",
    "        if label[i]=='FAIL' or label[i]=='Fail':\n",
    "            label[i]=np.float32(1)\n",
    "        elif label[i]=='SUCCESS' or label[i]=='Success':\n",
    "            label[i]=np.float32(0)\n",
    "        else:\n",
    "            print(i,' Error!')'''\n",
    "    label=label.astype(int)\n",
    "\n",
    "    return features,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21203956",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_df,label=get_clinical_features()\n",
    "#clinical_df=clinical_df[['CV','ST','PA','CD','RR','PS','TM']] #[['CV','PF','ST','PA','FV','CD','RR','PS','TM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c905ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>PF</th>\n",
       "      <th>ST</th>\n",
       "      <th>PA</th>\n",
       "      <th>FV</th>\n",
       "      <th>CD</th>\n",
       "      <th>RR</th>\n",
       "      <th>PS</th>\n",
       "      <th>TM</th>\n",
       "      <th>BRG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P-574</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-459</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-157</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-519</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-306</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-531</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-482</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CV  PF  ST   PA  FV  CD  RR  PS  TM  BRG\n",
       "P_No                                            \n",
       "P-574  0.5   0   0  0.0   1   0   0   0   0    1\n",
       "P-459  1.0   0   0  0.0   0   1   0   0   0    0\n",
       "P-157  1.0   0   0  0.0   0   1   0   0   0    1\n",
       "P-44   1.0   1   0  0.0   1   0   0   0   0    1\n",
       "P-519  1.0   1   0  0.0   1   0   0   0   0    0\n",
       "...    ...  ..  ..  ...  ..  ..  ..  ..  ..  ...\n",
       "P-33   1.0   1   0  0.5   1   0   0   0   0    1\n",
       "P-306  1.0   0   0  1.0   0   1   0   0   0    0\n",
       "P-340  0.0   1   0  0.5   0   0   0   0   1    1\n",
       "P-531  0.5   1   0  0.5   0   1   0   0   0    1\n",
       "P-482  1.0   1   0  0.0   0   1   0   0   0    1\n",
       "\n",
       "[657 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96943e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------0----------\n",
      "- Accuracy:  0.6060606060606061\n",
      "Confusion Matirx : \n",
      "[[65 14]\n",
      " [38 15]]\n",
      "- Sensitivity :  28.30188679245283\n",
      "- Specificity :  82.27848101265823\n",
      "\n",
      "\n",
      "----------1----------\n",
      "- Accuracy:  0.6212121212121212\n",
      "Confusion Matirx : \n",
      "[[68 11]\n",
      " [39 14]]\n",
      "- Sensitivity :  26.41509433962264\n",
      "- Specificity :  86.07594936708861\n",
      "\n",
      "\n",
      "----------2----------\n",
      "- Accuracy:  0.6136363636363636\n",
      "Confusion Matirx : \n",
      "[[67 12]\n",
      " [39 14]]\n",
      "- Sensitivity :  26.41509433962264\n",
      "- Specificity :  84.81012658227847\n",
      "\n",
      "\n",
      "----------3----------\n",
      "- Accuracy:  0.6136363636363636\n",
      "Confusion Matirx : \n",
      "[[67 12]\n",
      " [39 14]]\n",
      "- Sensitivity :  26.41509433962264\n",
      "- Specificity :  84.81012658227847\n",
      "\n",
      "\n",
      "----------4----------\n",
      "- Accuracy:  0.5833333333333334\n",
      "Confusion Matirx : \n",
      "[[64 15]\n",
      " [40 13]]\n",
      "- Sensitivity :  24.528301886792452\n",
      "- Specificity :  81.0126582278481\n",
      "\n",
      "Mean Accuracy :  60.757575757575765  %\n",
      "Mean Sensitivity :  26.41509433962264  %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy_list=[]\n",
    "sens_list=[]\n",
    "importance_list=[]\n",
    "\n",
    "for epoch in range(0,5):   \n",
    "    X_train,X_test,y_train,y_test=train_test_split(clinical_df,label,test_size=0.2,random_state=42)\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    \n",
    "    clf=RandomForestClassifier(n_estimators=50)\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    #print('- Prediction: ',pred)\n",
    "    #print('- Label: ',y_test.values)\n",
    "    importance_list.append(list(clf.feature_importances_))\n",
    "    \n",
    "    total=len(y_test)\n",
    "    cnt=0\n",
    "    for i in range(0,len(y_test)):\n",
    "        if pred[i]==y_test[i]:\n",
    "            cnt+=1\n",
    "    accuracy_list.append(cnt/total)\n",
    "    \n",
    "    CM=confusion_matrix(y_test.values, pred,labels=[0,1])\n",
    "    tn=CM[0][0]\n",
    "    tp=CM[1][1]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    sens_list.append((tp/(tp+fn)))\n",
    "    acc=np.sum(np.diag(CM)/np.sum(CM))\n",
    "    print()\n",
    "    print('----------'+str(epoch)+'----------')\n",
    "    print('- Accuracy: ',acc)\n",
    "    print('Confusion Matirx : ')\n",
    "    print(CM)\n",
    "    print('- Sensitivity : ',(tp/(tp+fn))*100)\n",
    "    print('- Specificity : ',(tn/(tn+fp))*100)\n",
    "    print()\n",
    "    \n",
    "#print(accuracy_list)\n",
    "print('Mean Accuracy : ',np.mean(accuracy_list)*100,' %')\n",
    "print('Mean Sensitivity : ',np.mean(sens_list)*100,' %')\n",
    "\n",
    "avg_importance=[sum(x)/len(importance_list) for x in zip(*importance_list)]\n",
    "\n",
    "columns=X_train.columns.values\n",
    "\n",
    "\n",
    "'''\n",
    "for t in X_train.columns.values:\n",
    "    columns.append(t[1])\n",
    "print(columns)\n",
    "'''\n",
    "  \n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "features = columns\n",
    "importance = avg_importance\n",
    "ax.set_title('Feature Importance')\n",
    "ax.bar(features,importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "59f6f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Prediction:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "- Label:  [1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1]\n",
      "- Prediction:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "- Label:  [1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1]\n",
      "- Prediction:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "- Label:  [1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1]\n",
      "- Prediction:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "- Label:  [1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1]\n",
      "- Prediction:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "- Label:  [1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1]\n",
      "[0.5909090909090909, 0.5909090909090909, 0.5909090909090909, 0.5909090909090909, 0.5909090909090909]\n",
      "Accuracy :  59.09090909090909  %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"fig = plt.figure()\\nax = fig.add_axes([0,0,1,1])\\nfeatures = columns\\nimportance = avg_importance\\nax.set_title('Feature Importance')\\nax.bar(features,importance)\\nplt.show()\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy_list=[]\n",
    "importance_list=[]\n",
    "\n",
    "for epoch in range(0,5):   \n",
    "    X_train,X_test,y_train,y_test=train_test_split(clinical_df,label,test_size=0.2,random_state=42)\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    \n",
    "    clf=SVC(gamma='auto')\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    print('- Prediction: ',pred)\n",
    "    print('- Label: ',y_test.values)\n",
    "\n",
    "    total=len(y_test)\n",
    "    cnt=0\n",
    "    for i in range(0,len(y_test)):\n",
    "        if pred[i]==y_test[i]:\n",
    "            cnt+=1\n",
    "    accuracy_list.append(cnt/total)\n",
    "    \n",
    "print(accuracy_list)\n",
    "print('Accuracy : ',np.mean(accuracy_list)*100,' %')\n",
    "\n",
    "columns=X_train.columns.values\n",
    "\n",
    "\n",
    "'''\n",
    "for t in X_train.columns.values:\n",
    "    columns.append(t[1])\n",
    "print(columns)\n",
    "'''\n",
    "  \n",
    "'''fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "features = columns\n",
    "importance = avg_importance\n",
    "ax.set_title('Feature Importance')\n",
    "ax.bar(features,importance)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380feef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
